
# Natural Language Processing using PyTorch
Hype around Deep Learning is centered mostly around Computer Vision, so are gateways to understanding most of the popular frameworks. With the recent advances around Language Technology/ Computational Linguistics or Natural Language Processing as popularly known, getting proper resources to engulf and fully understand the machinations behind it is arduous for starters.

Hence this project is inspired by specialization course of [Natural Language Processing](https://www.coursera.org/specializations/natural-language-processing) by [deeplearning.ai](https://www.deeplearning.ai/) offered through [Coursera](https://www.coursera.org) instructed by [Younes Bensouda Mourri](https://www.coursera.org/instructor/ymourri), [Łukasz Kaiser](https://www.coursera.org/instructor/lukaszkaiser), et.al.

`PyTorch` has been chosen due to its popularity in academia.

## NLP Tasks:
| Module | Content | Status |
|--|--|--|
| 2 | Neural network with GLoVe `word embeddings` to perform `sentiment analysis` of Tweets |  <ul><li> [ ] </li></ul>  |
| 2 | `Crosslingual Multi-Aspect` sentiment analysis using `sentence embeddings` |  <ul><li> [ ] </li></ul>  |
| 2 | `Generate` synthetic Shakespeare `text` using a Gated Recurrent Unit (`GRU`) language model |  <ul><li> [ ] </li></ul>  |
| 2 | Named Entity Recognition (`NER`) using `LSTM`s |  <ul><li> [ ] </li></ul>  |
| 2 | `Siamese` LSTM to analyse `similar` questions |  <ul><li> [ ] </li></ul>  |
| 2 | `Machine Translation` using `Attention` |  <ul><li> [ ] </li></ul>  |
<!---| 1 | `Basics`: <ul><li> Sentiment analysis of tweets using `logistic regression` and `naïve Bayes` </li><li>  `PCA` for dimension reduction of vector space</li><li>Translation using pre-trained embeddings with `locality sensitive hashing` and approximation with `k-nearest neighbor` search</li></ul> |  <ul><li> [ ] </li><li> [ ] </li><li> [ ] </li></ul>  |
| 1 | `Probabilistic Models`: <ul><li> Auto-correct algorithm using `Levenshtein`/`minimum edit distance` and n-gram language model </li><li>  `Viterbi` Algorithm for part-of-speech (`POS`) tagging</li><li>`Word2Vec` model that using continuous bag-of-words(`CBOW`)</li></ul> |  <ul><li> [ ] </li><li> [ ] </li><li> [ ] </li></ul>  |-->

